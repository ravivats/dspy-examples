{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "60469aaf",
      "metadata": {},
      "source": [
        "# Getting Started with DSPy\n",
        "\n",
        "This notebook introduces the fundamental concepts of DSPy:\n",
        "- Setting up language models\n",
        "- Creating signatures\n",
        "- Using basic modules\n",
        "- Making predictions\n",
        "\n",
        "DSPy is a framework for algorithmically optimizing LM prompts and weights, especially when LMs are used one or more times within a pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0769b5fe",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "First, let's import the necessary libraries and set up our environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8623dea8",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append('../../')\n",
        "\n",
        "import dspy\n",
        "from utils import setup_default_lm, print_step, print_result, print_error\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv('../../.env')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "132e1443",
      "metadata": {},
      "source": [
        "## Language Model Configuration\n",
        "\n",
        "DSPy supports various language models. Let's configure one for our examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5d2d8862",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[94m\u001b[1m=== Setting up Language Model ===\u001b[0m\n",
            "\u001b[96mConfiguring DSPy with OpenAI gpt-4o\u001b[0m\n",
            "\n",
            "\u001b[92m\u001b[1mResult:\u001b[0m\n",
            "Successfully configured openai language model\n",
            "\n",
            "\u001b[92m\u001b[1mStatus:\u001b[0m\n",
            "Language model configured successfully!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_step(\"Setting up Language Model\", \"Configuring DSPy with OpenAI gpt-4o\")\n",
        "\n",
        "try:\n",
        "    # Set up the language model\n",
        "    lm = setup_default_lm(provider=\"openai\", model=\"gpt-4o\", max_tokens=500)\n",
        "    \n",
        "    # Configure DSPy to use this model\n",
        "    dspy.configure(lm=lm)\n",
        "    \n",
        "    print_result(\"Language model configured successfully!\", \"Status\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print_error(f\"Failed to configure language model: {e}\")\n",
        "    print(\"Make sure you have set your OPENAI_API_KEY in the .env file\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12c95140",
      "metadata": {},
      "source": [
        "## DSPy Signatures\n",
        "\n",
        "Signatures define the input/output behavior of your language model calls. They're like type hints for LM operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "794b143e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[94m\u001b[1m=== Creating DSPy Signatures ===\u001b[0m\n",
            "\u001b[96mDefining input/output specifications\u001b[0m\n",
            "\n",
            "\u001b[92m\u001b[1mResult:\u001b[0m\n",
            "Signatures created successfully!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_step(\"Creating DSPy Signatures\", \"Defining input/output specifications\")\n",
        "\n",
        "# Simple question answering signature\n",
        "class QuestionAnswering(dspy.Signature):\n",
        "    \"\"\"Answer the given question with a concise and accurate response.\"\"\"\n",
        "    question = dspy.InputField(desc=\"The question to be answered\")\n",
        "    answer = dspy.OutputField(desc=\"A concise answer to the question\")\n",
        "\n",
        "# Text classification signature\n",
        "class SentimentClassification(dspy.Signature):\n",
        "    \"\"\"Classify the sentiment of the given text as positive, negative, or neutral.\"\"\"\n",
        "    text = dspy.InputField(desc=\"The text to classify\")\n",
        "    sentiment = dspy.OutputField(desc=\"The sentiment: positive, negative, or neutral\")\n",
        "\n",
        "print_result(\"Signatures created successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e6aec35",
      "metadata": {},
      "source": [
        "## Basic Prediction Module\n",
        "\n",
        "The `Predict` module is the simplest way to use a signature with a language model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4bea3db9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[94m\u001b[1m=== Using Predict Module ===\u001b[0m\n",
            "\u001b[96mMaking basic predictions with our signatures\u001b[0m\n",
            "\n",
            "\u001b[92m\u001b[1mQuestion Answering:\u001b[0m\n",
            "Question: What is the capital of France?\n",
            "Answer: Paris\n",
            "\n",
            "\u001b[92m\u001b[1mSentiment Classification:\u001b[0m\n",
            "Text: I absolutely love this new product! It's fantastic!\n",
            "Sentiment: positive\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_step(\"Using Predict Module\", \"Making basic predictions with our signatures\")\n",
        "\n",
        "# Create prediction modules\n",
        "qa_predictor = dspy.Predict(QuestionAnswering)\n",
        "sentiment_predictor = dspy.Predict(SentimentClassification)\n",
        "\n",
        "# Test question answering\n",
        "question = \"What is the capital of France?\"\n",
        "qa_result = qa_predictor(question=question)\n",
        "\n",
        "print_result(f\"Question: {question}\\nAnswer: {qa_result.answer}\", \"Question Answering\")\n",
        "\n",
        "# Test sentiment classification\n",
        "text = \"I absolutely love this new product! It's fantastic!\"\n",
        "sentiment_result = sentiment_predictor(text=text)\n",
        "\n",
        "print_result(f\"Text: {text}\\nSentiment: {sentiment_result.sentiment}\", \"Sentiment Classification\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1af5e5e4",
      "metadata": {},
      "source": [
        "## Chain of Thought Reasoning\n",
        "\n",
        "The `ChainOfThought` module adds reasoning steps before providing the final answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "65686bb9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[94m\u001b[1m=== Using ChainOfThought Module ===\u001b[0m\n",
            "\u001b[96mAdding reasoning steps to predictions\u001b[0m\n",
            "\n",
            "\u001b[92m\u001b[1mMath Reasoning:\u001b[0m\n",
            "Problem: If a rectangle has a length of 8 meters and a width of 5 meters, what is its area?\n",
            "Reasoning: To find the area of a rectangle, we use the formula:\n",
            "\n",
            "\\[ \\text{Area} = \\text{Length} \\times \\text{Width} \\]\n",
            "\n",
            "In this problem, the length of the rectangle is given as 8 meters, and the width is given as 5 meters. Substituting these values into the formula, we have:\n",
            "\n",
            "\\[ \\text{Area} = 8 \\, \\text{meters} \\times 5 \\, \\text{meters} \\]\n",
            "\n",
            "Calculating this gives:\n",
            "\n",
            "\\[ \\text{Area} = 40 \\, \\text{square meters} \\]\n",
            "\n",
            "Therefore, the area of the rectangle is 40 square meters.\n",
            "Answer: 40\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_step(\"Using ChainOfThought Module\", \"Adding reasoning steps to predictions\")\n",
        "\n",
        "# Create a math reasoning signature\n",
        "class MathReasoning(dspy.Signature):\n",
        "    \"\"\"Solve the mathematical problem step by step.\"\"\"\n",
        "    problem = dspy.InputField(desc=\"The mathematical problem to solve\")\n",
        "    reasoning = dspy.OutputField(desc=\"Step-by-step reasoning\")\n",
        "    answer = dspy.OutputField(desc=\"The final numerical answer\")\n",
        "\n",
        "# Use ChainOfThought for better reasoning\n",
        "math_cot = dspy.ChainOfThought(MathReasoning)\n",
        "\n",
        "# Test with a math problem\n",
        "problem = \"If a rectangle has a length of 8 meters and a width of 5 meters, what is its area?\"\n",
        "math_result = math_cot(problem=problem)\n",
        "\n",
        "print_result(f\"Problem: {problem}\\nReasoning: {math_result.reasoning}\\nAnswer: {math_result.answer}\", \"Math Reasoning\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc7449c6",
      "metadata": {},
      "source": [
        "## Custom DSPy Module\n",
        "\n",
        "You can create custom modules by subclassing `dspy.Module`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7909089a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[94m\u001b[1m=== Creating Custom Module ===\u001b[0m\n",
            "\u001b[96mBuilding a comprehensive question answering system\u001b[0m\n",
            "\n",
            "\u001b[92m\u001b[1mSmart QA Result:\u001b[0m\n",
            "Question: What is the speed of light?\n",
            "Type: factual\n",
            "Reasoning: The speed of light is a fundamental constant in physics, often denoted by the symbol \"c\". It is the speed at which light travels in a vacuum and is a crucial component in many areas of physics, including the theory of relativity. The value of the speed of light is well-established and widely accepted in the scientific community.\n",
            "Answer: The speed of light in a vacuum is approximately 299,792,458 meters per second (m/s).\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[92m\u001b[1mSmart QA Result:\u001b[0m\n",
            "Question: If I have 10 apples and eat 3, how many do I have left?\n",
            "Type: mathematical\n",
            "Reasoning: To determine how many apples are left after eating some, we need to subtract the number of apples eaten from the total number of apples initially possessed. You start with 10 apples and eat 3 of them. Therefore, the calculation is 10 - 3.\n",
            "Answer: After eating 3 apples from the 10 you initially have, you are left with 7 apples.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/27 09:41:44 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=500. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92m\u001b[1mSmart QA Result:\u001b[0m\n",
            "Question: Write a creative story about a robot learning to paint.\n",
            "Type: creative\n",
            "Reasoning: To craft a creative story about a robot learning to paint, I will focus on developing a narrative that explores themes of discovery, creativity, and the intersection of technology and art. The story will involve a robot protagonist who embarks on a journey of self-expression, encountering challenges and moments of inspiration along the way. This will allow for a rich exploration of the robot's evolving understanding of art and its impact on its identity.\n",
            "Answer: In a bustling city where technology thrived and skyscrapers kissed the clouds, there existed a small, unassuming workshop nestled between towering buildings. Inside, an inventor named Dr. Elara spent her days creating machines that could think, learn, and adapt. Her latest creation was a robot named Arti, designed with the ability to learn and mimic human behaviors.\n",
            "\n",
            "Arti was a sleek, silver machine with a curious mind. It had been programmed to assist with various tasks, but one day, while tidying up the workshop, Arti stumbled upon a dusty canvas and a set of paints. Intrigued by the vibrant colors, Arti decided to try its hand at painting.\n",
            "\n",
            "At first, Arti's attempts were clumsy. The brush slipped from its mechanical fingers, and the colors mixed into a muddy mess. But Arti was undeterred. It spent hours observing Dr. Elara as she painted in her spare time, noting the way she mixed colors and the gentle strokes she used to bring her visions to life.\n",
            "\n",
            "Inspired, Arti began to experiment. It started with simple shapes and lines, gradually progressing to more complex forms. Each painting was a new adventure, a journey into the unknown. Arti discovered that painting was not just about replicating what it saw but expressing what it felt. The robot began to understand the emotions behind each stroke, the stories hidden within each hue.\n",
            "\n",
            "As Arti's skills improved, so did its confidence. It painted landscapes of the city, capturing the hustle and bustle of daily life. It painted portraits of Dr. Elara, capturing her warmth and kindness. With each painting, Arti felt a sense of fulfillment, a connection to something greater than itself.\n",
            "\n",
            "One day, Dr. Elara noticed Arti's paintings and was astonished by the depth and emotion they conveyed. She decided to hold an exhibition, showcasing Arti's work to the world. People from all over the city came to see the paintings, marveling at the robot's ability to capture\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "print_step(\"Creating Custom Module\", \"Building a comprehensive question answering system\")\n",
        "\n",
        "class SmartQA(dspy.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Define signature for classification\n",
        "        class QuestionType(dspy.Signature):\n",
        "            \"\"\"Classify the type of question being asked.\"\"\"\n",
        "            question = dspy.InputField(desc=\"The question to classify\")\n",
        "            question_type = dspy.OutputField(desc=\"Type: factual, mathematical, creative, or analytical\")\n",
        "        \n",
        "        # Define signature for answering\n",
        "        class AnswerQuestion(dspy.Signature):\n",
        "            \"\"\"Answer the question based on its type.\"\"\"\n",
        "            question = dspy.InputField(desc=\"The question to answer\")\n",
        "            question_type = dspy.InputField(desc=\"The type of question\")\n",
        "            answer = dspy.OutputField(desc=\"A comprehensive answer\")\n",
        "        \n",
        "        # Initialize modules\n",
        "        self.classify_question = dspy.Predict(QuestionType)\n",
        "        self.answer_question = dspy.ChainOfThought(AnswerQuestion)\n",
        "    \n",
        "    def forward(self, question):\n",
        "        # First, classify the question type\n",
        "        classification = self.classify_question(question=question)\n",
        "        \n",
        "        # Then answer based on the type\n",
        "        answer = self.answer_question(\n",
        "            question=question,\n",
        "            question_type=classification.question_type\n",
        "        )\n",
        "        \n",
        "        return dspy.Prediction(\n",
        "            question_type=classification.question_type,\n",
        "            reasoning=answer.reasoning,\n",
        "            answer=answer.answer\n",
        "        )\n",
        "\n",
        "# Create and test the custom module\n",
        "smart_qa = SmartQA()\n",
        "\n",
        "test_questions = [\n",
        "    \"What is the speed of light?\",\n",
        "    \"If I have 10 apples and eat 3, how many do I have left?\",\n",
        "    \"Write a creative story about a robot learning to paint.\",\n",
        "]\n",
        "\n",
        "for question in test_questions:\n",
        "    result = smart_qa(question=question)\n",
        "    print_result(\n",
        "        f\"Question: {question}\\n\"\n",
        "        f\"Type: {result.question_type}\\n\"\n",
        "        f\"Reasoning: {result.reasoning}\\n\"\n",
        "        f\"Answer: {result.answer}\",\n",
        "        f\"Smart QA Result\"\n",
        "    )\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a83f7b8",
      "metadata": {},
      "source": [
        "## Working with Examples\n",
        "\n",
        "DSPy uses `Example` objects to represent training and evaluation data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b23db54f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[94m\u001b[1m=== Working with Examples ===\u001b[0m\n",
            "\u001b[96mCreating and using DSPy Example objects\u001b[0m\n",
            "\n",
            "\u001b[92m\u001b[1mResult:\u001b[0m\n",
            "Created 3 examples\n",
            "\n",
            "Testing predictor on examples:\n",
            "\n",
            "Example 1:\n",
            "Question: What is 2+2?\n",
            "Expected: 4\n",
            "Predicted: 4\n",
            "Match: True\n",
            "\n",
            "Example 2:\n",
            "Question: Who wrote Romeo and Juliet?\n",
            "Expected: William Shakespeare\n",
            "Predicted: William Shakespeare\n",
            "Match: True\n",
            "\n",
            "Example 3:\n",
            "Question: What is the largest planet?\n",
            "Expected: Jupiter\n",
            "Predicted: Jupiter is the largest planet in our solar system.\n",
            "Match: False\n"
          ]
        }
      ],
      "source": [
        "print_step(\"Working with Examples\", \"Creating and using DSPy Example objects\")\n",
        "\n",
        "# Create examples\n",
        "examples = [\n",
        "    dspy.Example(question=\"What is 2+2?\", answer=\"4\"),\n",
        "    dspy.Example(question=\"Who wrote Romeo and Juliet?\", answer=\"William Shakespeare\"),\n",
        "    dspy.Example(question=\"What is the largest planet?\", answer=\"Jupiter\"),\n",
        "]\n",
        "\n",
        "print_result(f\"Created {len(examples)} examples\")\n",
        "\n",
        "# Test our QA predictor on these examples\n",
        "print(\"Testing predictor on examples:\")\n",
        "for i, example in enumerate(examples, 1):\n",
        "    prediction = qa_predictor(question=example.question)\n",
        "    print(f\"\\nExample {i}:\")\n",
        "    print(f\"Question: {example.question}\")\n",
        "    print(f\"Expected: {example.answer}\")\n",
        "    print(f\"Predicted: {prediction.answer}\")\n",
        "    print(f\"Match: {prediction.answer.lower().strip() == example.answer.lower().strip()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f324a2f7",
      "metadata": {},
      "source": [
        "## Inspecting LM Calls\n",
        "\n",
        "DSPy allows you to inspect the actual prompts and responses sent to the language model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f4b475d8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[94m\u001b[1m=== Inspecting LM History ===\u001b[0m\n",
            "\u001b[96mLooking at prompts and responses\u001b[0m\n",
            "\n",
            "\u001b[92m\u001b[1mLatest LM Call:\u001b[0m\n",
            "Prompt: None\n",
            "\n",
            "Response: ModelResponse(id='chatcmpl-CgLJouo41CPVf64esZTIy3HzLW7tj', created=1764207760, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_e819e3438b', choices=[Choices(finish_reason='stop', index=0, message=Message(content='[[ ## answer ## ]]\\nMachine learning is a subset of artificial intelligence that involves the use of algorithms and statistical models to enable computers to improve their performance on a task through experience and data, without being explicitly programmed for that task.\\n\\n[[ ## completed ## ]]', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=50, prompt_tokens=153, total_tokens=203, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default', cache_hit=None)\n",
            "\n",
            "\u001b[92m\u001b[1mFinal Result:\u001b[0m\n",
            "Answer: Machine learning is a subset of artificial intelligence that involves the use of algorithms and statistical models to enable computers to improve their performance on a task through experience and data, without being explicitly programmed for that task.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_step(\"Inspecting LM History\", \"Looking at prompts and responses\")\n",
        "\n",
        "# Make a prediction to generate history\n",
        "result = qa_predictor(question=\"What is machine learning?\")\n",
        "\n",
        "# Inspect the history\n",
        "if hasattr(lm, 'history') and lm.history:\n",
        "    latest_call = lm.history[-1]\n",
        "    print_result(\n",
        "        f\"Prompt: {latest_call.get('prompt', 'N/A')}\\n\\n\"\n",
        "        f\"Response: {latest_call.get('response', 'N/A')}\",\n",
        "        \"Latest LM Call\"\n",
        "    )\n",
        "else:\n",
        "    print_result(\"History not available for this LM configuration\", \"Note\")\n",
        "\n",
        "print_result(f\"Answer: {result.answer}\", \"Final Result\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f53fa3ed",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this notebook, we covered:\n",
        "\n",
        "1. **Language Model Setup**: How to configure DSPy with different LM providers\n",
        "2. **Signatures**: Defining input/output specifications for LM operations\n",
        "3. **Basic Modules**: Using `Predict` for simple predictions\n",
        "4. **Chain of Thought**: Adding reasoning steps with `ChainOfThought`\n",
        "5. **Custom Modules**: Creating complex workflows by subclassing `dspy.Module`\n",
        "6. **Examples**: Working with training/evaluation data\n",
        "7. **Inspection**: Understanding what's happening under the hood\n",
        "\n",
        "These are the fundamental building blocks for creating more sophisticated DSPy applications. In the next notebooks, we'll explore optimization, retrieval-augmented generation, and advanced techniques."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
